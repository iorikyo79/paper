과접합정의 ; 모델이 노이즈 및 관련없는 세부 사항을 포함하여 훈련 데이터를 너무 잘 학습해서 훈련 데이터에 편향된 결과가 나오는것. 훈련데이터에 대해 너무 잘 수행되지만 신규 데이터에는 성능이 저하됨.
과적합과 과소적합의 주요 차이점
- 훈련 데이터 성능 : 과적합은 훈련 정확도가 높고, ㅅ과소적합은 훈련 정확도 낮음
- 테스트/검증 데이터의 성능
과적합은 보이지 않는 데이터에서 성능이 저하
-모델 복잡성 : 과적합은 과도한 모델 복잡성으로인해 발생. 과소적합은 모델이 지나치게 단순해서 발생.

ㅂ편향-분산 절출 : 과대적합은 분산이 높고 편향이 낮음.
과소 적합은 편향이 높고 분산이 낮다.

데이터 유출 : 학습 데이터 외부의 정보를 사용해 모델을 생성시 발생. 기능 선택이나 데이터 대체와 같은 데이터 전처리 단계가 테스트 세트를 포함한 전체 데이터 세트의 정보를 사용할때 발생할수 있다.

편견 : 단순한 모델로 실제 문제 근사시 발생하는 오류.
변화 : 분산은 모델의 예측이 다양한 훈련 데이터 셋에 대해 얼마나 변동하는지를 측정하는것.고분산 모델은 지나치게 복잡하고 훈련 데이터의 작은 변동에 민감하며 훈련 데이터 세트에서 노이즈를 포착한다.ㅇ이로인해 과적합이 발생하고 기계학습 모델은 신규 데이터에서 성능 저하

편향-분산 트레이드오프
모델 성능의 편향과 분산 사이의 관계를 보여준다.

잔차분석
잔차는 관측된 값과 모델 예측값 간의 차이. 잔차 분석에는 잔차의 패턴과 분포를 조사하여 모델 적합성과 관련된 잠재적 문제를 식별하는 작업이 포함.
이상적으로 잔차가 무작위로 분포되어야 하며 식별할수 있는 패턴이나 추세가 없어야 한다. 잔차의 구조화된 패턴은 모델에 중요한 특징이 누락되었거나 기본 가정을 위반 했음을 나타낼수 있다.

적합도 테스트
적합도 테스트는 모델의 예측이 관찰된 데이터와 얼마나 잘 일치하는지 정량적 측정. 일반적으로 테스트 통계량을 계산하고 이를 임계값 또는 p-값과 비교하여 모델과 데이터 간의 편차의 유의성을 결정하는 작업이 포함.

평가지표
특정 작업에 대한 모델의 성능을  요약하는 정량적 측정값. 회귀, 분류, 순위지정과 같은 다양한 유형의 문제에는 다양한 측정 항목이 적합.일반적 평가지표
- 회귀문제 : 평균제곱오차(MSE) 제곱평균오차제곱근(RMSE), R제곱
- 분류문제 : 정확도, 정밀도, 재현율, F1 스코어, AUROC

진단플롯
잔차플롯, QQ, 

컴퓨터 비전의 과적합 원인
- 데이터 크기에 비해 복잡한 모델
- 소음 훈련데이터 : 훈련 데이터가 제대로 구성되었는지. 노이즈가 없는지 확인해야한다
- 불충분한 정규화 : L1, L2 정규화, 드랍아웃, early stopping과 같은 정규화 기술은 딥러닝 모델의 과적합을 막는데 필수.

훈련/검증 세트 간 데이터 유출
- 학습중 학습/검증/테스트 데이터 모두에서 모델성능을 추정
- 검증/테스트 오류가 증가하거나 안정되기  시작하는 동안 훈련 오류가 계속 감소한다면 과적합.

과적합 방지법
- 데이터 증대 : 회전 뒤집기 크기조정 변화등 데이터셋 다양성과 가변성 높일수 있음
- 주석이 달린 샘플의 클래스 분포 관찰 및 모니터링
: 주석을 추가하는 동안 데이터세트의 클래스 분포를 관찰해야함.
특정 클래스가 과소 대표되는 경우 활성 학습을 사용해 해당 소스 클래스의 레이블이 지정되지 않은 샘플에 레이블을 지정하는 우선순위를 지정.
- early stop : 훈련중 검증세트에 대한 모델 성능을 모니터링하는 정규화 기술. 검증 손실이 감소하지 않거나 증가하기 시작하면 모델이 훈련데이터에 과적합된고 있음을 나타낼 수 있음. 이러한 경우 추가 과적합을 ㅂ방지하기 위해 훈련 프로세스를 조기에 중단.
-dropout : 
- L1, L2 정규화 : 손실 함수에 페널티 항을 추가하여 모델이 큰 가중치를 갖지 않도록함. 

전이학습.

!!! 현재 훈련단계에서 모델 과적합을 확인할수 있는 방법이 없음.
과적합 확인을 위한 데이터셋 재구성 필요
학습중 학습/검증/테스트 모두에서 모델 성능 확인하자.
학습에서만 성능이 올라가고 테스트에서 성능이 내려간다면 과적합.
