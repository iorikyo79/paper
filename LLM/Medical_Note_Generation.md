 # A Continued Pretrained LLM Approach for Automatic Medical Note Generation
 ## 제목: 자동 의료 노트 생성을 위한 지속적 사전학습 LLM 접근법

### Abstract:
대형 언어 모델(Large Language Models, LLMs)은 자연어 처리 분야에 혁신을 가져오고 있습니다. 그러나 GPT-4와 같은 최신 LLM의 사용은 대부분의 전문 분야에서 비용이 매우 높아 활용이 어려운 실정입니다.
우리는 의료 대화에 특화되어 개발된 최초의 지속적 학습 **LLaMA2 기반 13B 규모의 LLM인 HEAL**을 소개합니다. HEAL은 **PubMedQA에서 GPT-4와 PMC-LLaMA를 능가하는 78.4%의 정확도**를 보여줍니다. 또한 **의료 노트 생성 측면에서는 GPT-4와 동등**한 성능을 보입니다.
주목할 만한 점은, HEAL이 **GPT-4와 Med-PaLM 2보다 더 많은 정확한 의학 개념을 식별**해 내며, **정확성과 완전성 측면에서 사람 스크라이브(scribe)와 다른 유사 모델들의 성능을 능가**한다는 것입니다.

### 1. Introduction
대형 언어 모델(LLM)의 등장은 자연어 처리와 이해 분야에 혁명적인 변화를 가져왔고, 법률, 금융, 의료 등 여러 영역에서 AI의 실용적 활용을 가능케 했습니다. GPT-4, Med-PaLM 2와 같은 사유 LLM과 LLaMA2 같은 오픈소스 LLM은 일반 NLP 벤치마크에서 뛰어난 성능을 보여주고 있습니다.

그러나 최근 연구에 따르면, Orca, Phi-2와 같이 더 작은 LLM이더라도 더 특화된 데이터셋으로 지속 학습(continued training)을 하면 일반적인 작업에서 훨씬 더 큰 LLM의 성능을 능가할 수 있다고 합니다.  LLM이 일반적인 성능에서는 성공을 거두고 있지만, 정밀성과 깊이 있는 이해가 중요한 의료와 같은 특수 분야에서는 종종 부족한 모습을 보입니다.
의료 대화를 기록하는 것은 잠재적인 전사 오류와 구어체 특유의 복잡성 때문에 사람과 기계 모두에게 어려운 작업인데, 기존의 의료 LLM은 이 문제를 제대로 다루지 못하고 있습니다.  의료 데이터로 학습된 기존 LLM은 의료 질의응답 같은 문제는 잘 해결하지만, 전자건강기록(EHR)에 호환되는 종합적인 의료 노트를 만드는 데는 어려움을 겪습니다.
**일부 의료 분야 맞춤형 LLM은 노트의 일부 구성 요소는 작성할 수 있지만 핵심적인 "주관적(Subjective)" 부분은 누락하는 경우가 많습니다. 일부 파인튜닝된 모델은 의료 대화에서 노트를 생성할 수 있지만 사람의 감독이 필요합니다.**
전반적으로 우리는 의료 대화를 해석하는데 능숙한 새로운 의료 LLM을 개발했습니다. **의료 및 일반 웹 말뭉치, GPT-4 작업 지침, EHR 등 다양한 데이터에 대한 지속적인 사전학습과 설명 튜닝(explanation tuning) 기법을 활용**하여, 이 모델은 의사가 승인한 의료용 SOAP 노트를 생성할 수 있게 되었습니다.
우리의 주요 공헌은 다음과 같습니다:

알려진 바로는 우리가 최초로, **의사-환자 대화에서 사람의 개입없이 사람 수준의 품질을 뛰어넘는 의사 승인 의료 노트를 생성할 수 있는 소형(13B) 의료 LLM을 구축**했습니다.
HEAL은 Med-PaLM 2와 동일한 크기의 다른 공개 모델을 능가하고, 의료 노트 생성에서 GPT-4의 성능에 필적하며, 가장 높은 완전성을 보여줍니다.
모델 크기가 작음에도 불구하고 **PubMedQA에서 78.4%의 정확도를 달성하여 GPT-4를 능가하고 Med-PaLM 2의 성능과 5% 내의 격차**를 보였습니다.


### 2. 지속적 사전학습

#### 2.1 데이터셋
우리는 모델이 일관된 영어 문장을 생성하고, 의료 내용을 이해하며, 의료 노트 생성에 필요한 복잡한 지침을 수행할 수 있도록 하기 위해 세 가지 주요 출처에서 학습 데이터를 수집했습니다. (표 1 참조)
![image](https://github.com/iorikyo79/paper/assets/11941673/5ac6c3a1-7ae7-46cc-84c1-07ee94e0e3cc)

**비의료 공개 데이터셋**: 사전학습된 LLaMA2 모델의 생성 능력을 잃지 않도록 C4와 같은 일반 도메인 데이터셋을 추가했습니다. 이러한 데이터셋에 대한 지속적인 사전학습은 생성 작업에 매우 중요하며 모델의 문법과 구문 구성 능력을 향상시킵니다. 처음에는 open-subtitle과 youtube에서 필터링한 자막 데이터도 포함했지만, 품질이 낮아 모델 성능에 부정적인 영향을 미쳐 제외하기로 결정했습니다.

**의료 공개 데이터셋**: 모델의 의학 지식이 지속 학습 후에도 유지되도록 nih.gov 같은 의료 웹 도메인에서 데이터를 필터링하여 다양한 의료 개념 이해와 의학 지식 재현에 활용했습니다. MedDialog는 의료 언어 대화를, PubMed 논문 같은 읽기 자료는 전반적인 의료 맥락을 제공했습니다. PubMed와 필터링된 웹 의료 말뭉치가 최종 학습 데이터셋에서 각각 약 **25억 토큰**씩 기여했습니다.

**독점 의료 데이터셋**: 우리는 또한 미국의 실제 의사-환자 대화, 전자건강기록(EHR), SOAP(Subjective, Objective, Assessment, and Plan) 노트, ROS(Review of System) 템플릿 등으로 구성된 비식별화된 독점 의료 데이터셋을 구축했습니다. 또한 의료 대화에서 약물 추출이나 생성된 의료 노트의 문법 교정 같은 의료 지침으로 구성된 합성 데이터셋도 만들었습니다. 이러한 지침은 사람과 GPT-3.5/GPT-4의 도움을 받아 생성되었습니다. 일부 지침에는 상세한 설명도 포함했습니다.
이런 설명이 포함된 지침으로 학습하면 모델이 의료 노트를 더 잘 이해하고 그 이면의 추론을 파악할 수 있게 되는데, 이는 특히 하위 의료 문서화 작업에 필요합니다.

예를 들어, 대화에서 정보를 검색하도록 요청하는 **의료 Instruction**을 만들었습니다:
```
"당신은 의료 대화 요약을 전문으로 하며, 사람들이 증거를 가지고 당신의 요약을 신뢰할 수 있도록 명확하고 철저한 설명을 제공합니다. 제 의사와 저의 대화 중 일부 대본이 있습니다.
작업: 이 대화에서 <목표 내용>을 요약하세요.
요구사항: <요구사항>.
대본: <대본>"

You specialize in summarizing medical conversations, providing clear and thorough explanations so that people can trust your summary with evidence. I have part of a transcript from a conversation between my doctor and myself.
Task: Summarize the <targeted content> from this conversation.
Requirements: <requirements>
Transcript: <transcript>
```
그 다음 생성된 노트 검토에 대한 지침도 만들었습니다:
```
"당신의 임무는 주어진 의료 노트를 검토하고 업데이트된 노트를 생성하는 것입니다.
규칙: <검토 방법에 대한 규칙>. 의료 노트에 필요한 모든 업데이트를 '업데이트'로 나열하세요.업데이트된 의료 노트를 '업데이트된 의료 노트'로 반환하세요.
대본: <대본>
의료 노트: <의료 노트>"

Your job is to review a given medical note and generate an updated note.
Rules: <rules on how to review>. List all the needed updates for the medical note as Updates. Return the updated medical note as Updated Medical Note.
Transcript: <transcript>
Medical Note: <medical note>
```
마지막으로 이 두 가지를 모두 요약 작업에 대한 모델의 이해를 향상시키기 위해 학습에 사용했습니다. 우리는 60B 토큰 이상을 포함하는 훨씬 더 큰 고품질 맞춤형 데이터셋을 개발했지만, 현재 이 학습에는 14.89B 토큰만 사용되었습니다.

#### 2.2 학습 상세 내용
우리는 FSDP(Fully Sharded Data Parallel) 파이프라인 병렬화와 하이브리드 샤딩(hybrid sharding), Flash Attention을 사용하여 32개의 A100 80GB GPU에서 학습을 수행했습니다. 학습률(learning rate)은 처음에 5e-5로 설정하고, 코사인 스케줄에 따라 1e-5까지 감소하도록 함. 학습률이 너무 높으면 모델이 불안정해지고, 너무 낮으면 학습이 더뎌지기 때문. 또한, 배치 크기를 256으로 비교적 작게 잡았는데, 그 덕분에 10,000번 이상의 미니배치 업데이트를 진행할 수 있었음. 미니배치를 많이 하면 모델이 데이터의 다양한 패턴을 익히는 데 도움이 됨.
의료 대화는 30분을 초과하고 문맥 길이가 4K를 넘을 수 있습니다. 이를 위해 위치 인코딩(positional encoding)을 보간(interpolation)하는 기법을 써서 기존 모델을 확장하여 8K 문맥 길이를 사용. 가중치 감쇠(weight decay)는 0.1로, warm-up step count는 50으로 설정했습니다. (가중치 감쇠는 모델이 과적합되는 걸 막아주고, 워밍업은 학습 초기에 모델이 안정적으로 수렴할 수 있게 도와줌.)

**견고한 학습(Robust Training)**: 기계 및 실험 관련 오작동에 내성을 갖도록, 고정 시드(fixed seed)와 체크포인트를 사용했고, 학습 데이터를 n개의 하위 집합으로 나누는 단계별 학습(phased training)을 구현했습니다. 특정 검증 하위 집합의 손실이 안정화되기 시작하면 효율성을 위해 다음 단계에서 샘플링 비율을 줄였습니다. 이렇게 하면 특정 검증 세트의 손실이 수렴하기 시작할 때 다음 단계에서는 해당 세트의 샘플링 비율을 낮춰서 학습 효율을 높일 수 있음.

**데이터 패킹 & 중복 제거(Dedup)**: 최대 시퀀스 길이에 맞추기 위해 문장 단위로 데이터를 패킹했습니다. 또한 데이터 품질을 개선하기 위해 데이터 중복을 제거했습니다.

**손실(Loss)**: C4, 공개 의료 자료를 포함한 일반 말뭉치에 대해서는 모든 토큰에 대해 경사를 계산했습니다. 그러나 독점 지침 데이터에서는 응답 토큰에 대해서만 손실을 계산했습니다.
```
일반적으로 손실을 최소화하는 방향으로 모델의 가중치를 업데이트합니다.

일반 코퍼스(general corpus)의 경우:
C4나 공개 의료 자료 같은 일반 코퍼스에서는 모든 토큰에 대해 경사(gradient)를 계산.
즉, 입력 시퀀스의 모든 토큰이 손실 계산에 동일하게 기여.
이는 일반적인 언어 모델 학습 방식으로, 입력 시퀀스 전체를 학습에 활용하여 언어의 전반적인 패턴을 학습하는 데 도움이 됨.

독점 지침 데이터(proprietary instruction data)의 경우:
반면 독점 지침 데이터에서는 응답 토큰(response tokens)에 대해서만 손실을 계산.
여기서 '응답 토큰'은 주어진 지침(instruction)에 대한 모델의 생성 결과를 의미.
지침 데이터는 일반적으로 '지시문(instruction)'과 '응답(response)' 쌍으로 구성되는데,
이 경우 지시문은 프롬프트(prompt)로 주어지고 모델은 이에 대한 적절한 응답을 생성해야 함.

따라서 독점 지침 데이터에서는 프롬프트 부분은 제외하고 모델이 생성한 응답 부분에 대해서만
손실을 계산하여, 모델이 지침을 정확히 수행하는 방향으로 학습되도록 유도한 것임.
이는 모델이 프롬프트의 패턴이나 언어 특성 자체를 학습하기보다는, 주어진 지시를 잘 이해하고
그에 맞는 적절한 응답을 생성하는 능력을 기르는 데 초점을 맞추기 위한 것으로 볼 수 있음.
이러한 차별적인 손실 계산 방식은 학습 데이터의 특성과 모델이 학습해야 할 핵심 능력을 고려한 전략적 선택.
일반 코퍼스에서는 언어의 전반적인 패턴 학습에,
독점 지침 데이터에서는 지침 수행 능력 향상에 보다 집중하여 모델을 효과적으로 학습시키기 위한 방법으로 볼 수 있음.
```

![image](https://github.com/iorikyo79/paper/assets/11941673/3c8b221a-648f-43ed-b336-53dc17ed41d3)

### 3. 평가
이 섹션에서는 지속적 사전학습 결과와 평가 방법론을 일부 보여줍니다.

#### 3.1 사전학습
우리는 사전학습을 모니터링하기 위해 두 가지 평가 방법을 사용했습니다. 첫째, 모든 데이터 소스에 걸쳐 복잡도(perplexity)를 측정했습니다. 검증 세트를 사용하여 모델이 각 소스에서 얼마나 효율적으로 학습하는지 추적했습니다.
그림 1은 EHR과 MIMIC IV 노트에 대한 평가의 하위 집합입니다. EHR 노트는 우리의 독점 데이터셋에서 샘플링한 1,000개의 노트로, 실제 진료 방문에서 의사가 작성한 노트입니다. MIMIC IV 노트는 공개 데이터셋에서 샘플링한 1,000개의 비식별화된 중환자 치료 노트입니다.
그림 1은 학습이 진행됨에 따라 모델이 두 데이터 세트를 점진적으로 더 잘 이해하게 되었음을 보여줍니다. 그러나 MIMIC IV의 복잡도가 훨씬 더 낮은 것으로 보아, 기본 LLaMA2 모델이 초기 사전학습 과정에서 이 데이터셋으로 학습되었을 가능성이 있습니다.
둘째, 생성 품질에 대한 전체적인 이해를 위해 몇 가지 few-shot(3-shot) 생성 작업을 검증에 사용했습니다. 여기에는 다음이 포함됩니다:

장문 생성(Long text generation): 이 작업은 의사와 환자 간의 의료 대화록에서 SOAP 노트의 주관적(Subjective) 섹션의 여러 범주를 요약하는 것과 관련이 있습니다. 예를 들면:

프롬프트: 주어진 텍스트에서 환자의 주 호소(chief complaint)를 요약하세요.
대화록: <대화록>
출력: <응답>

중문 생성(Medium text generation): 의료 대화록에 대한 질의응답 작업입니다. 우리는 수집한 대화록 데이터셋에 Alpaca 파이프라인을 수정하여 이 데이터를 만들었습니다. GPT-4에 대화록을 기반으로 몇 단어에서 한 문장에 이르는 응답을 요구하는 질문을 생성하도록 요청했습니다. 예를 들면:

프롬프트: 환자의 현재 약물을 파악하세요.
대화록: <대화록>
출력: <응답>

단문 생성(Short text generation): 신체 시스템 식별(다중 선택)과 증상의 유무(단일 선택)를 포함한 ROS(Review of System) 관련 분류 작업으로 구성됩니다. 예를 들면:

프롬프트: 환자가 지속적인 슬픔, 흥미 또는 식욕 변화 등 우울증 징후를 보이나요?
대화록: <대화록>
출력: <응답>
우리는 작업 1, 2에 대해 Rouge-cls를, 작업 3에 대해 정확도를 측정하여 사전학습 성능을 모니터링했습니다. 각 평가 데이터셋에는 1,000개의 예시가 있습니다.
그림 2는 우리 모델의 성능이 장문 및 중문 생성과 다중 선택 분류에서 꾸준히 향상되었음을 보여줍니다. 그러나 단일 선택 분류에서는 유의미한 개선이 관찰되지 않았습니다. 우리는 이를 이미 높은 정확도 수치와, 모델을 더 작은 관련 데이터셋에서 별도로 학습시켰을 때 추가적인 개선이 나타난 사실에 기인한다고 보았으며, 이는 스케일업된 학습으로 잠재적 향상이 가능함을 시사합니다.

#### 3.2 사전학습 절제(Ablation)
표 2는 우리의 맞춤형 15B 데이터셋을 축소한 버전에서 파생된 1B 토큰 데이터셋을 사용하여 7B LLaMA2 모델에서 데이터 비율 변화의 영향을 조사한 결과입니다.
절제 연구 결과, 학습 데이터 구성에서 일반 데이터셋을 제거하면 모델의 생성 능력에 해롭게 작용하여 요약 품질이 저하되는 것으로 나타났습니다. 또한 의료 데이터셋이 실제로 모델의 의료 맥락 이해를 개선했다는 결론을 내릴 수 있었습니다.
결과적으로 우리는 학습 과정에서 이들 데이터셋을 동일한 비율로 사용하여 모델의 생성 능력을 유지하면서 의료 맥락에 대한 이해를 향상시키기로 결정했습니다.

#### 3.3 의료 노트 생성
**평가 데이터셋 및 설정**: 우리는 HEAL 모델을 표 3에 나와있는 GPT-4, GPT-3.5, Med-PaLM 2와 같은 여러 일반 및 의료 SOTA 모델들, 그리고 유사한 크기의 다른 오픈소스 의료 LLM들과 비교했습니다.
LLaMA2-Chat-13B와 PMC-LLaMA-13B 모델은 3.1절에서 상세히 설명한 다양한 길이의 의료 생성 작업에 대해 10K 지침 샘플을 사용하여 세심하게 파인튜닝했습니다. LLaMA2-13B, PMC-LLaMA의 기본 모델인 MedLLaMA, Meditron-7B 같은 사전학습된 모델은 지침 수행 능력을 향상시키기 위해 50만 개 예제로 구성된 우리의 독점 데이터셋에서 설명 튜닝을 거쳤습니다.
우리는 또한 이러한 모델들을 우리 생산 시스템의 사람 스크라이브(내부 스크라이브 교육을 받고 서비스에 대해 금전적 보상을 받은 의대생)와 비교했습니다. 모든 모델과 스크라이브는 평균 12분 분량의 10개 의사-환자 대화 스타일 대화를 사용하여 SOAP 의료 노트의 주관적(Subjective)과 계획(Plan) 섹션을 생성하는 작업으로 평가되었습니다.
**평가 지표**: 우리는 이러한 모델을 평가하기 위해 인간 의료 전문가를 활용했습니다. 그들은 각 대화록에 대해 모든 필수 의료 정보를 별도의 의료 엔티티로 강조 표시한 루브릭 노트(rubric note)를 개발했습니다.
모든 엔티티는 의료 제공자가 노트를 승인하는 데 필요한 중요한 문장이나 구를 나타냅니다. 평균적으로 우리 전문가들은 대화록당 35개의 의료 엔티티를 식별했습니다. 우리는 생성된 노트를 완전성(Completeness), 정확성(Correctness), 간결성(Conciseness)의 세 가지 핵심 매개변수로 평가했습니다:

누락 정보(Missed Information)는 루브릭 노트 대비 테스트 노트에서 생략된 엔티티를 나타냅니다. 이 지표는 테스트 노트의 완전성을 반영합니다.
부정확한 정보(Incorrect Information)는 테스트 노트에서 부정확하게 포착된 엔티티를 의미합니다. 잘못된 정보가 AI에 대한 신뢰를 저하시킬 수 있으므로 정보의 정확성이 필수적인 의료 분야에서 이 지표는 매우 중요합니다.
무관한 정보(Irrelevant Information)는 루브릭 노트와 연결되지 않은 테스트 노트의 불필요한 요소를 가리킵니다. 길고 장황한 의료 노트는 검토에 더 많은 시간이 소요되므로 무관한 정보를 줄이는 것이 중요합니다.

**결과 및 분석** : 표 3은 우리 HEAL 모델과 다른 모델들, 그리고 사람 스크라이브의 성능을 비교한 것입니다. 특히 HEAL은 누락 정보 지표에서 다른 모든 모델을 능가하며, 이는 중요한 의료 정보를 식별하고 요약하는 우수한 능력을 나타냅니다.
우리는 이러한 성능 향상을 복잡한 의료 지침을 사용한 지속적 사전학습 접근 방식에 기인한다고 봅니다. ASR(Automatic Speech Recognition) 오류로 인한 부정확성도 일부 관찰되었지만, 우리 모델과 GPT-4는 이러한 실수를 교정하는 데 뛰어났습니다.
사람 스크라이브와 Med-PaLM 2는 간결한 노트를 작성했지만 중요한 의료 세부 정보를 누락했습니다. GPT-3.5, MedLLaMa, LLaMA2-chat 등 다른 모델들은 높은 부정확 및 누락 정보 점수에서 보듯 실제 대화의 뉘앙스를 파악하는 데 어려움을 겪었습니다.
전반적으로 우리 모델은 이 작업의 모든 지표에서 뛰어난 성능을 보이며, 사람 스크라이브와 다른 파인튜닝된 모델들을 능가합니다. 상세 품질 평가에서 우리는 사람 스크라이브가 의료 노트를 작성하는 데 오디오 녹음 시간의 약 1.67배가 걸린다는 것을 발견했습니다. 그러나 AI 모델은 거의 즉시 동일한 노트를 생성할 수 있어, 의료 전사에서 AI의 효율성과 시간 절약 능력을 보여줍니다.

#### 3.4 공개 벤치마크
HEAL은 의료 노트 요약에 특화되어 설계되었지만, 우리는 다른 의료 작업에서의 효율성을 평가하기 위해 두 가지 인기 있는 의료 벤치마크에서 다른 LLM과 성능을 비교해 보았습니다.
**PubMedQA** (Jin et al., 2019): 해당 PubMed 논문 발췌문을 사용하여 예/아니오/아마도로 연구 질문에 답하는 생물의학 QA 작업입니다.
**MedQA** (Jin et al., 2021): 미국 의사 면허 시험에서 추출한 다지선다형 문제입니다.
PubMedQA에서 Med-PaLM 2는 거대한 크기와 PubMedQA 데이터에 대한 추가 튜닝을 활용하여 최고 점수를 달성했습니다. 표 4에서 보듯이, HEAL은 튜닝 후 78.4%의 정확도를 달성하여 GPT-4의 성능을 능가했고, 파인튜닝된 LLaMA2와 75B PubMed 데이터로 추가 튜닝된 PMC-LLaMA보다도 우수했습니다.
우리의 성능 향상은 의료 이해에 초점을 맞춘 대화 데이터에 대한 독점 의료 지침 데이터 때문인 것으로 보입니다.
MedQA에서 우리는 47.2%의 정확도를 달성하여 LLaMA2 13B 모델은 능가했지만 PMC-LLaMA에는 미치지 못했습니다. MedQA는 의료 추론에 초점을 맞추고 있어, 모델이 의학 지식을 상기하고 주어진 문제에서 진단이나 해결책을 도출해내야 합니다.
GPT-4, Med-PaLM 2 같이 더 큰 모델이나 방대한 양의 데이터로 학습된 모델이 이 작업에서 본질적으로 유리합니다. 의료 대화 해석에 특화된 HEAL은 이 작업과 잘 맞지 않아 이 데이터셋에서 최적의 성능을 내지 못했습니다.

### 4. 결론
이 논문은 의료 대화를 이해하고 요약할 수 있는 의료 LLM 개발 작업을 소개합니다. 그 결과, 훨씬 적은 매개변수로 Med-PaLM 2, PMC-LLaMA 등 기존 의료 LLM을 능가하고 GPT-4와 동등한 성능을 보이는 최초의 모델이 만들어졌습니다.

우리의 평가는 소규모 LLM의 지속적 사전학습만으로도 놀라운 성과를 거둘 수 있음을 보여줍니다. 우리는 학습 규모를 확대하면 결과를 더욱 개선할 수 있을 것이라 믿습니다. 우리의 연구는 의료 문서화와 기타 의료 분야에서 유망한 발전을 제시합니다.

### 5. 관련 연구
**의료 LLM**: MedGPT, Med-PaLM 2 등 다양한 의료 LLM은 여러 의료 데이터셋으로 학습하면 의학 지식 이해 작업에서 모델 성능이 향상됨을 보여줍니다. 최신 오픈소스 LLM인 MEDITRON-70B와 PMC-LLaMA는 작업별 파인튜닝과 지침 튜닝의 효과를 입증합니다.

**영역 적응 LLM**: Gururangan et al. (2020), Beltagy et al. (2019)가 보여주듯이, 무标주(unlabeled) 영역별 데이터에 대한 지속적 사전학습은 해당 영역 작업에서 모델 성능을 높여주며, 처음부터 영역 적응형 사전학습을 위한 자원이 제한적일 때 실용적인 해결책을 제공합니다.
**의료 노트 생성**: Zhang et al. (2021), Van Veen et al. (2023)의 선행 연구는 언어 모델을 사용하여 대화에서 의료 요약을 생성하는 것이 가능함을 보여주었습니다. 그러나 이들은 주로 부분적인 노트 생성이나 사람의 개입이 필요한 반자동 방법을 목표로 했을 뿐, 종합적이고 의사 승인이 가능한 보고서 작성은 목표로 하지 않았습니다.
**설명 튜닝(Explanation tuning)**: Orca 모델은 건전한 추론이 가능한 작은 언어 모델도 복잡한 작업을 효율적으로 수행할 수 있음을 보여주었습니다. 이들은 GPT-4 같은 더 큰 모델을 교사로 사용하여 LLaMA2 13B 모델을 설명 튜닝함으로써 학습되었습니다.

### 6. 윤리적 고려사항
모든 데이터 처리와 실험은 HIPAA 준수 환경에서 이루어졌습니다. 우리는 데이터 규정 준수 협약에 따라 PHI 정보를 제거하기 위해 임상 데이터를 비식별화했습니다.

HEAL은 요약, 대화 기반 Q&A, 노트 검토와 같은 내부 의료 작업에만 사용됩니다. 모든 프롬프트는 의도치 않은 사용을 방지하기 위해 감사를 거칩니다.

### 7. 한계점
우리의 설계는 대화의 맥락 이해와 요약에 초점을 맞추고 있으며, MedQA나 유사한 벤치마크에서는 더 많은 의료 데이터 학습을 통해 더욱 개선될 수 있습니다.

향후 프로젝트에서는 더 정교한 기본 모델을 활용하고, 의료 지식과 추론 내용의 균형을 맞춘 더 높은 품질의 데이터를 선별하며, 실험 규모를 확대하는 방안을 모색해 볼 수 있습니다.
